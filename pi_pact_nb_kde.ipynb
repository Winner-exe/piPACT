{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier with Kernel Density Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains a Naive Bayes Classifier with KDEs to predict the distance between the Raspberrry Pis. The code below is adapted from Chapter 5 of Jake VanderPlas' *Python Data Science Handbook* and utilizes the `KDECLassifier` class from the same source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "from pi_pact_sort import categorize, bin_categorize\n",
    "\n",
    "FEATURES: list = ['RSSI', 'HUMIDITY', 'PRESSURE'] # Contains strings 'RSSI', 'HUDMITIY', and/or 'PRESSURE'\n",
    "CATEGORIZE_FUNC = bin_categorize # One of the two binning functions in pi_pact_sort.py\n",
    "\n",
    "# Automatically configure other variables\n",
    "if len(FEATURES) > 1:\n",
    "    if len(FEATURES) == 2:\n",
    "        if 'HUMIDITY' in FEATURES:\n",
    "            feature_str = '3varH'\n",
    "        else:\n",
    "            feature_str = '3varP'\n",
    "    else:\n",
    "        feature_str = '4var'\n",
    "else:\n",
    "    feature_str = '2var'\n",
    "\n",
    "if CATEGORIZE_FUNC == categorize:\n",
    "    label_str = '3b'\n",
    "else:\n",
    "    label_str = 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kde_classifier import KDEClassifier\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "DROP_COLUMNS = ['ADDRESS', 'TIMESTAMP', 'UUID', 'MAJOR', 'MINOR', 'TX POWER', 'TEMPERATURE',\n",
    "                'PITCH', 'ROLL', 'YAW', 'SCAN']\n",
    "for feature in ['RSSI', 'HUMIDITY', 'PRESSURE']:\n",
    "    if feature not in FEATURES:\n",
    "        DROP_COLUMNS.append(feature)\n",
    "SAMPLE_SIZE = 30000\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "\"\"\"Creates a Naive Bayes classifier with KDE to predict a distance range given RSSI values and other variables.\n",
    "\n",
    "   KDEClassifier class adapted from Chapter 5 of the Python Data Science Handbook by Jake VanderPlas:\n",
    "   https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html\n",
    "\"\"\"\n",
    "\n",
    "# Initialize DataFrame\n",
    "data: pd.DataFrame = pd.DataFrame(columns=['DISTANCE',] + FEATURES)\n",
    "data_copy: pd.DataFrame = data.copy()\n",
    "csv_file: Path\n",
    "for csv_file in Path('.').glob('indoor-noObstruct-SenseHat*/*.csv'):\n",
    "    datapart: pd.DataFrame = pd.read_csv(csv_file)\n",
    "    for column in DROP_COLUMNS:\n",
    "        if column in datapart.columns:\n",
    "            datapart = datapart.drop([column], 1)\n",
    "    data_copy = data_copy.append(datapart)\n",
    "\n",
    "# Categorize distance\n",
    "data_copy['DISTANCE'] = data_copy['DISTANCE'].map(CATEGORIZE_FUNC)\n",
    "\n",
    "# Sample data from each distance category\n",
    "for value in data_copy['DISTANCE'].unique():\n",
    "    datapart = data_copy[data_copy.DISTANCE == value]\n",
    "    datapart = datapart.sample(SAMPLE_SIZE, random_state=1)\n",
    "    data = data.append(datapart)\n",
    "\n",
    "# Assign features and labels\n",
    "X: np.array = data.drop(['DISTANCE'], 1).to_numpy()\n",
    "y: np.array = data['DISTANCE'].to_numpy(dtype=int)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "# Code adapted from Chapter 5 of the Python Data Science Handbook by Jake VanderPlas:\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html\n",
    "bandwidths = np.around(np.linspace(0.5, 1, 5), decimals=4)\n",
    "grid = GridSearchCV(KDEClassifier(), {'bandwidth': bandwidths}, n_jobs=2)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print optimal parameters and accuracy\n",
    "print(grid.best_params_)\n",
    "print('accuracy =', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle model\n",
    "with open(f\"nb-kde-models/{feature_str}-{label_str}-nb-kde-model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(grid.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot an ROC curve\n",
    "if CATEGORIZE_FUNC == bin_categorize:\n",
    "    probs = grid.best_estimator_.predict_proba(X)\n",
    "    fpr, tpr, _ = roc_curve(y, probs[:, 1])\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate')\n",
    "    plt.xlim(0,)\n",
    "    plt.ylim(0,)\n",
    "    plt.savefig(str(Path(f'./nb-kde-models/{feature_str}-{label_str}-nb-kde-model-roc-curve.png')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
